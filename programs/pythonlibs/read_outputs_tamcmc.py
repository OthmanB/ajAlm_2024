'''
Library to handle outputs from the TAMCMC in python
'''
import numpy as np
from subprocess import call, DEVNULL
import os
import matplotlib.pyplot as plt
from zipfile import ZipFile

def read_covarmat(dir_tamcmc_outputs, process_name, phase='A', chain=0):

	#file2=dir_tamcmc_outputs + '/' + process_name + '/restore/' + process_name + '_restore_' + phase + '_2.dat'  # FILE WITH SIGMA
	#file3=dir_tamcmc_outputs + '/' + process_name + '/restore/' + process_name + '_restore_' + phase + '_3.dat'  # File with the covarmat
	file2=os.path.join(dir_tamcmc_outputs, process_name, "restore", process_name + '_restore_' + phase + '_2.dat')
	file3=os.path.join(dir_tamcmc_outputs, process_name, "restore", process_name + '_restore_' + phase + '_3.dat')
	Nchains, Nvars, iteration, variable_names, sigmas, sigmas_mean, mus, mus_mean=read_restore_file2(file2)
	Nchains, Nvars, iteration, variable_names, covarmats=read_restore_file3(file3)
	c=sigmas[chain] * covarmats[chain, :, :] # Calculates the covariance matrix of the coldest chain using sigma and the covmat
	return c

def read_restore_file2(filename):
	'''
		Read the restore files with the index = 2
		This file contains sigma and mu, the scaling factors of the MALA algorithm
	'''
	f=open(filename)
	txt=f.read()
	f.close()
	data=txt.split('\n')
	header=[]
	loglikelihood=[]
	logprior=[]
	logposterior=[]
	for d in data:
		s=d.split()
		if len(s) !=0:
			if s[0] == '#':
				header.append(d)
			if s[0] == '!':
				v=s[1].split('=') # Separate the value from the rest to be able to pick the value
				if v[0] == 'Nchains':
					Nchains=int(d.split('=')[-1]) 
				if v[0] == 'Nvars':
					Nvars=int(d.split('=')[-1]) 
				if v[0] == 'iteration':
					iteration=int(d.split('=')[-1]) 
				if v[0] == 'variable_names':
					st=d.split('=')[-1]
					variable_names=st.split()					
				if v[0] == 'sigmas':
					st=d.split('=')[-1]
					sigmas=np.asarray(st.split(), dtype=float)
				if v[0] == 'sigmas_mean':
					st=d.split('=')[-1]
					sigmas_mean=np.asarray(st.split(), dtype=float)
	for i in range(len(data)):
		s=data[i].split()
		if len(s) !=0:
			if s[0] == '!':
				v=s[1].split('=') # Separate the value from the rest to be able to pick the value
				if v[0] == 'mus':
					mus_raw=data[i+1:i+1+Nchains]
					mus=np.zeros((Nchains, Nvars))
					for k in range(len(mus_raw)):
						mus[k,:]=mus_raw[k].split()
				if v[0] == 'mus_mean':
					mus_raw=data[i+1:i+1+Nchains]
					mus_mean=np.zeros((Nchains, Nvars))
					for k in range(len(mus_raw)):
						mus_mean[k,:]=mus_raw[k].split()
	return Nchains, Nvars, iteration, variable_names, sigmas, sigmas_mean, mus, mus_mean

def read_restore_file3(filename):
	'''
		Read the restore files with the index = 3
		This file contains the covarmats of the MALA algorithm
	'''
	f=open(filename)
	txt=f.read()
	f.close()
	data=txt.split('\n')
	header=[]
	loglikelihood=[]
	logprior=[]
	logposterior=[]
	for d in data:
		s=d.split()
		if len(s) !=0:
			if s[0] == '#':
				header.append(d)
			if s[0] == '!':
				v=s[1].split('=') # Separate the value from the rest to be able to pick the value
				if v[0] == 'Nchains':
					Nchains=int(d.split('=')[-1]) 
				if v[0] == 'Nvars':
					Nvars=int(d.split('=')[-1]) 
				if v[0] == 'iteration':
					iteration=int(d.split('=')[-1]) 
				if v[0] == 'variable_names':
					st=d.split('=')[-1]
					variable_names=st.split()				
	for i in range(len(data)):
		s=data[i].split()
		if len(s) !=0:
			if s[0] == '!':
				v=s[1].split('=') # Separate the value from the rest to be able to pick the value
				if v[0] == 'covarmats':
					covarmats=np.zeros((Nchains, Nvars, Nvars))
					i0=i+2					
					for j in range(Nchains):
						covarmat_raw=data[i0:i0+Nvars]
						for k in range(Nvars):
							covarmats[j, k,:]=covarmat_raw[k].split()
						i0=i0+Nvars+1
	return Nchains, Nvars, iteration, variable_names, covarmats

def getmodel_bin(model_name, params, plength, xr, cpp_path='cpp_prg', outdir='tmp/', 
				read_output_params=True, data_type='range', verbose=False):
	'''
		Build a model using the model_name and the params parameters.
		Warning: Requires getmodel v1.84.0. 
		dir_tamcmc_outputs: The roott directory that contains all of the outputs. The process outputs must be in a subdirectory of this directory
		model_name: Name of the model, as specified in the .model file
		params: A vector of parameters that follow exactly the syntax expected for the model_name
		plength: A vector of parameters specifying the structure of the params list
		xr: IF data_type == 'range':
					A vector of 3 values used to generate a x-axis by getmodel [xmin, xmax, resolution]
			ELSE IF data_type == 'file':
					A full path to the data file
		read_output_params: If True, the program will not only the output model but also the outputs parameters file generated by getmodel that format all of the parameters in a nice format
							This is important if you want to know the frequencies, heights, widths, splittings of l=1 mixed modes for example.
							The result is returned as a dictionary with keys.
	'''
	if data_type == 'range':
		str_xrange=str(xr[0]) + ',' + str(xr[1]) + ',' + str(xr[2])
	else:
		str_xrange=xr

	#params_file=outdir + '/model_params.txt' # File for the parameters of the model that is read by getmodel
	#outfile=outdir + '/model_data.txt' # Output file with 2 columns: x-axis and model-axis
	params_file=os.path.join(outdir, "model_params.txt") # File for the parameters of the model that is read by getmodel
	outfile=os.path.join(outdir, "model_data.txt") # Output file with 2 columns: x-axis and model-axis
	header="# This file contains in the first line, the parameters structure (plength). All following lines, correspond to a single vector of parameters"
	header=header + "\n# File generated by getmodel_bin in read_outputs_tamcmc.py\n"
	f=open(params_file, 'w')
	f.write(header)
	for p in plength:
		f.write("{0:d}  ".format(int(p)))
	f.write('\n')
	for p in params:
		f.write("{}  ".format(p))
	f.write('\n')
	f.close()
	# Call the getmodel function
	print(' Calling getmodel...')
	print(' Current dir :', os.getcwd())
	print(' Command: ', cpp_path + "./getmodel",' ', str_xrange,' ', params_file,' ', model_name, ' ', outfile, " data_type=range")
	if data_type == 'range':
		if verbose == True:
			call([cpp_path + "./getmodel", str_xrange, params_file, model_name, outfile, "data_type=range"])
		else:
			call([cpp_path + "./getmodel", str_xrange, params_file, model_name, outfile, "data_type=range"], stdout=DEVNULL, stderr=DEVNULL)
	else:
		if verbose == True:
			call([cpp_path + "./getmodel", str_xrange, params_file, model_name, outfile, "data_type=file"])
		else:
			call([cpp_path + "./getmodel", str_xrange, params_file, model_name, outfile, "data_type=file"], stdout=DEVNULL, stderr=DEVNULL)
	x,model=read_getmodel_out(outfile)
	if read_output_params==False:
		if verbose == True:
			call(["rm", outfile])
			call(["rm", params_file])
		else:
			call(["rm", outfile], stdout=DEVNULL, stderr=DEVNULL)
			call(["rm", params_file], stdout=DEVNULL, stderr=DEVNULL)			
		return x, model
	else:
		outfile_params=outdir + '/params_0.model'
		modelname, plength, raw_params, mode_params, noise_params, xrange_params, mode_params_names, mixed_modes_params_dic=read_paramsfile_getmodel(outfile_params)
		params_dic=make_params_dic(modelname, plength, raw_params, mode_params, noise_params, xrange_params, mode_params_names, mixed_modes_params_dic)
		# We remove the temporary files after reading them... avoid issues
		if verbose == True:
			call(["rm", outfile])
			call(["rm", params_file])
		else:
			call(["rm", outfile], stdout=DEVNULL, stderr=DEVNULL)
			call(["rm", params_file], stdout=DEVNULL, stderr=DEVNULL)			
		#call(["rm", outfile_params])
		return x,model, params_dic

def make_params_dic(modelname, plength, raw_params, mode_params, noise_params, xrange_params, mode_params_names, mixed_modes_params_dic):
	params_dic={"modelname":modelname, "xrange":xrange_params, "modes":{"params": mode_params, "param_names": mode_params_names}, "noise":noise_params, 
			"raw":{"plength":plength, "params":raw_params}, "mixedmodes":mixed_modes_params_dic}
	return params_dic

def test_getmodel_bin():
	dir_tamcmc_outputs='/Users/obenomar/Work/Benomar2022/Data/MCMC_Simulation_data/HNR30_a1ovGamma0.6_Tobs1460_Equatorial/outputs/0000004.0/outputs/'
	model_name='model_MS_Global_aj_HarveyLike'
	plength=[18.000000,   2.0000000,  18.000000,   17.000000,   18.000000,   0.0000000,   14.000000,   18.000000,   10.000000,   1.0000000,   2.0000000]
	#params_file='/Users/obenomar/Work/Benomar2022/Data/MCMC_Simulation_data/HNR30_a1ovGamma0.6_Tobs1460_Equatorial/products/0000004.0/best_models_params.txt'
	params=[0.54061583,   0.74591736,   1.3842204,   1.6677060,   2.4035411,   3.9737417,   6.1266122,   8.2190896,   14.081630,   6.4293650,   12.904589,   4.1542549,   
		1.4088523,   0.53174518,   0.43467690,   0.085851187,   0.099866973,   0.0071462766,   1.5021981,   0.44837225,   
		1287.7398,   1391.6491,   1494.9732,   1598.6803,   1700.8838,   1802.2827,   1904.5405,   2007.5080,   2110.8359,   2214.0570,   2317.1895,   2420.6195,   
		2524.2488,   2628.4444,   2734.1416,  2839.0349,   2945.2929,   3051.4348,   
		1334.1387,   1437.7106,   1541.9705,   1644.9806,   1747.1640,  1849.0069,   1952.0169,   2055.4822,   2159.1303 ,  2262.5165,  2366.1740,   
		2470.2832,   2574.6883,   2679.4859,   2784.2501,   2889.9446,   2995.0919,   
		1279.4899,   1383.9151,   1487.7133,   1591.1504,   1693.9335,   1795.7044,  1898.1979,   2001.5935,  2105.1738,   2208.8328,   2312.4044,   
		2416.4141,   2521.1328,   2625.9137,   2729.4635,   2835.6162,   2939.1613,   3042.9986,   
		1.0324487,   0.0000000,  0.026826358,  0.0000000,   0.0000000,   0.0000000,   0.0057421062,   
		0.0000000,   0.0000000,   0.0000000,   0.0000000,  0.0000000,   0.0000000,   0.0000000,   1.2091705,  0.92823539,   1.0989029,   1.3903554,   
		1.4591096,   1.4606692,   1.4494607,   1.5453552,   1.4012211,   2.5585729,  1.5776260,   2.8895497,  5.0604240,   7.1791160,  5.7052496,   
		13.474484,   5.5146227,  19.057416,   0.0000000,   0.0000000,   1.0000000,   0.0000000,   0.0000000,   1.0000000,  0.77035371,  5.6856232,   
		1.7176610,   0.084528003,  39.531957,   30.000000,   0.0000000]
	#outdir='../tmp/model/'
	#cpp_path='../cpp_prg/'
	xr=[1000, 2000, 0.1]
	os.chdir('../cpp_prg')
	outdir='../tmp/model/'
	cpp_path=''
	x, model, params_dic=getmodel_bin(dir_tamcmc_outputs, model_name, params, plength, xr, cpp_path=cpp_path, outdir=outdir, read_output_params=True)
	os.chdir('source')


def getstats_bin(dir_tamcmc_outputs, process_name, phase='A', chain=0, first_index=0, 
					period=1, erase_tmp=True, cpp_path='cpp_prg/', outdir='tmp/',
					version="1.86.6", verbose=False):
	'''
		Convert a binary output file from the tamcmc process into a simple text format
		The function makes use of the get_stats program created upon compilation of the tamcmc program
		dir_tamcmc_outputs: The roott directory that contains all of the outputs. The process outputs must be in a subdirectory of this directory
		core_filename: The name of the process that was ran (eg. 'aj_ARonly_Sun'). This is the name listed in the config_presets.cfg of the tamcmc program
		phase: The phase of the analysis
		chain: The chain index that need to be unpacked
		outfile: The name of the output file
		version: If version="1.86.6" (default), use the boost::option system. Otherwise, use the old option system
		18 nov 2022 Addition: introducing first_index and period. REQUIRES getstats compiles with TAMCMC v>1.83.5
		18 Dec 2023 Addition: version 1.86.6 new statemen (see condition). 
	'''
	outfile=outdir + '/posteriors.txt'
	core_filename=os.path.join(dir_tamcmc_outputs,process_name, "outputs", process_name + '_' + phase + '_stat_criteria')
	if verbose == True:
		if version != "1.86.6":
			call([cpp_path + "./getstats", core_filename, str(chain), outfile, str(first_index), str(-1), str(period)])
		else:
			call([cpp_path + "./getstats", "-i", core_filename, "-o", outfile, "-c", str(chain), "-S", str(first_index), "-L",str(-1), "-p", str(period)])
	else:
		if version != "1.86.6":
			call([cpp_path + "./getstats", core_filename, str(chain), outfile, str(first_index), str(-1), str(period)], stdout=DEVNULL, stderr=DEVNULL)
		else:
			call([cpp_path + "./getstats", "-i", core_filename, "-o", outfile, "-c", str(chain), "-S", str(first_index), "-L",str(-1), "-p", str(period)], stdout=DEVNULL, stderr=DEVNULL)

	loglikelihood, logprior, logposterior, header, labels=getstats_txt(outfile)
	if erase_tmp == True:
		process = os.remove(outfile)
	return loglikelihood, logprior, logposterior

def bin2txt(dir_tamcmc_outputs, process_name, phase='A', chain=0, 
	    	first_index=0, last_index=-1, period=1, single_param_index=-1,
	    	erase_tmp=True, cpp_path='cpp_prg/', cpp_version="1.85.0", outdir='tmp/', 
			get_plength=False, verbose=False):
	'''
		A function that calls bin2txt and read the outputs in order to return the samples for each parameters in a matrix form
		update on 18 Nov 2022: adding isfixed output: Specifies if a parameters is fixed or is a variable
		update on 1 Dec 2022: adding get_plength: If True, we return also plength
		update on 25 Jul 2023: adding cpp_version: Set to allow cross-compatibility with older version of TAMCMC 
	'''
	#core_filename=dir_tamcmc_outputs + '/' + process_name + '/outputs/' + process_name + '_' + phase + '_params'
	core_filename=os.path.join(dir_tamcmc_outputs,process_name, "outputs", process_name + '_' + phase + '_params')
	ok=False
	if cpp_version == "1.84.0":
		if verbose == True:
			call([cpp_path+"./bin2txt", core_filename, str(chain), outdir, str(first_index), str(last_index), str(period)])
		else:
			call([cpp_path+"./bin2txt", core_filename, str(chain), outdir, str(first_index), str(last_index), str(period)], stdout=DEVNULL, stderr=DEVNULL)
		ok=True
	if cpp_version == "1.85.0": # ">1.85.0"
		if version == True:
			call([cpp_path+"./bin2txt", "--rootname", core_filename, "--chain-index", str(chain), 
				"--output-dir", outdir, "--first-kept-element", str(first_index), "--last-kept-element", str(last_index), 
				"--periodicity", str(period), "--single-param-index", str(single_param_index)])
		else:
			call([cpp_path+"./bin2txt", "--rootname", core_filename, "--chain-index", str(chain), 
				"--output-dir", outdir, "--first-kept-element", str(first_index), "--last-kept-element", str(last_index), 
				"--periodicity", str(period), "--single-param-index", str(single_param_index)], stdout=DEVNULL, stderr=DEVNULL)
		ok=True
	if ok == False:
		print("Error: cpp_version must be either '1.84.0' or '1.85.0' (for v>1.85.0). This controls the formating for calling bin2txt")
		print("       Check the content of these TAMCMC versions in order to see the difference.")
		exit()
	# Iterate over all of the available files in the directory
	files=get_files_list(outdir, extension='.ASCII')
	if len(files) != 0:
		print(' bin2txt executed successfully')
	else:
		print('Error: No ASCII files in the tmp directory.')
		print('       It is likely that bin2txt failed to read the TAMCMC data')
		print('       Check manually the settings of bin2txt:')
		print('           - Program Location: cpp_prg/./bin2txt' )
		print('           - Root File Names     : ', core_filename )
		print('           - Chain Index         : ', chain)
		print('           - Output Directory    : ', outdir)
		print('           - First Index         : ', first_index)
		print('           - Last Index          : ', last_index)
		print('           - Period              : ', period)
		if cpp_version == "1.85.0":
			print('           - single-param-index  : ', single_param_index)
		print('       Executed command: ')
		if cpp_version == "1.84.0":
			print('           '+cpp_path +'./bin2txt ', core_filename, ' ', str(chain), ' ', outdir, ' ', str(first_index), ' ',  str(last_index), ' ', str(period))
		else:
			print("           "+cpp_path+"./bin2txt ", " --rootname ", core_filename, " --chain-index ", str(chain), 
				" --output-dir ", outdir, " --first-kept-element ", str(first_index), " --last-kept-element ", str(last_index), 
				" --periodicity ", str(period), " --single-param-index ", str(single_param_index))			

		print(' --- ')	
		exit()

	# Get the number of samples from the first file
	if single_param_index == -1:
		samples, varname=read_bin2txt_out(outdir + '000.ASCII')
		Nsamples=len(samples)
		if Nsamples == 1: # If the first parameter was fixed, try with the second one
			samples, varname=read_bin2txt_out(outdir + '001.ASCII')
			Nsamples=len(samples)
	else:
		if cpp_version == "1.84.0":
			print("Warning: single_param_index option is provided (!= -1) while this argument is for cpp_version>1.85.0 (specified user version 1.84.0)")
			print("         Ignoring the option...")
			samples, varname=read_bin2txt_out(outdir + '000.ASCII')
			Nsamples=len(samples)
			if Nsamples == 1: # If the first parameter was fixed, try with the second one
				samples, varname=read_bin2txt_out(outdir + '001.ASCII')
				Nsamples=len(samples)
		else:
			samples, varname=read_bin2txt_out(outdir + files[0])
			Nsamples=len(samples)
	
	print('Nsamples=', Nsamples)
	# Read plength.txt ...
	if get_plength == True:		
		plength=read_plength(outdir + "plength.txt")
	smcmc=np.zeros((Nsamples, len(files)))
	labels=[]
	isfixed=[]
	for f in files:
		if cpp_version == "1.85.0" and  single_param_index != -1:
			index=0
		else:	
			index=int(f.split('.')[0]) # index of the parameter
		samples, varname=read_bin2txt_out(outdir + f)
		labels.append(varname.strip())
		smcmc[:,index]=samples
		if len(samples) == 1:
			isfixed.append(True)
		else:
			isfixed.append(False)
	# erase files in the temporary directory
	if erase_tmp == True:
		for f in files:
			process = os.remove(outdir+f)
		process = os.remove(outdir+'plength.txt')
	if get_plength == False:
		return smcmc, labels, isfixed
	else:
		return smcmc, labels, isfixed, plength

def getevidence(dir_tamcmc_outputs, process_name, phase='A', interpolation_factor=1000, 
	    	first_index=0, last_index=-1, period=7, bootstrap_method="block",
			bootstrap_Nsamples=2000, boostrap_blocksize_percent=1,
	    	erase_tmp=True, cpp_path='cpp_prg/', extension_name='_evidence_bootstrap.txt', outdir=None,
			verbose=False):

	core_filename=os.path.join(dir_tamcmc_outputs, process_name , "outputs" , process_name + '_' + phase)
	if outdir == None:
		output_file=os.path.join(dir_tamcmc_outputs, process_name, "diags", process_name + '_' + phase + extension_name)
	else:
		output_file=os.path.join(outdir, process_name + '_' + phase + extension_name)
	cmd=[cpp_path +"./getevidence", "-i", core_filename, "-o", output_file,
	   		"-f", str(interpolation_factor), "-S", str(first_index), "-L", str(last_index), 
			"-p", str(period), "-b", str(bootstrap_method), "-n", str(bootstrap_Nsamples),
			"--bootstrap-blocksize-percent", str(boostrap_blocksize_percent)]
	if verbose == True:
		call(cmd)
	else:
		call(cmd, stdout=DEVNULL, stderr=DEVNULL)
	evidence, evidence_err=read_global_likelihood(output_file, evidence_only=True, bootstrap_on=True)
	return evidence, evidence_err

def test_bin2txt(cpp_version="1.84.0"):
	dir_tamcmc_outputs='/Users/obenomar/tmp/test_a2AR/tmp/Realdata/activity_TAMCMC/28-06-2022/ajfits/'
	process_name='aj_ARonly_Sun_19992002'
	bin2txt(dir_tamcmc_outputs, process_name, phase='A', chain=0, first_index=0, period=1, erase_tmp=True, cpp_version=cpp_version)

def read_paramsfile_getmodel(file_in):
	'''
		Function that read the formated outputs generated by the code model of TAMCMC and returned by the getmodel tools of TAMCMC
		It reads the file by searching blocks of data (delimited by specific "#" comments) and single entries (delimited by "=" separating a keyword and the value)
		In principle blocks and single entries do not need to be in a specific order (although this was not tested. I tested only the usual structure at the time of writting: 30Nov2022)
		file_in: input file to be read. Must be an output of the TAMCMC model functions (either directly made by cpptamcmc -debug mode- or by getmodel)
	'''
	handled_mixed_models=['model_RGB_asympt_a1etaa3_AppWidth_HarveyLike_v4']
	Nkey1_expected_mixed=[14]
	mixed_modes_params_dic={}
	f=open(file_in,'r')
	txt=f.read()
	f.close()
	data=txt.split('\n')
	Nkey1_expected=3 # It is expected that this key is used for "Model =", "raw_params =", "plength =" only
	Nkey1=0
	Nkey2=0
	# The arrays of values with # as first line of comment should be: "Spectrum parameters", "Configuration of mode parameters" and "Configuration of noise parameters"
	# In case of mixed modes, we should also have: # Mixed mode global parameters [...], and # Mixed mode local parameters [...] 
	Nkey2_expected=5
	i=0
	while i < len(data) and Nkey2 <= Nkey2_expected:
		d=data[i]
		key1=d.split('=')
		key2=d.split('#')
		if len(key1) == 2: # The key is valid if it is not commented by "#" as first character of the line
			if key1[0].strip() == "Model" and d[0] != "#":
				print(key1[1])
				for h in range(len(handled_mixed_models)):
					if key1[1].strip() == handled_mixed_models[h]:
						Nkey1_expected=Nkey1_expected_mixed[h]
				modelname=key1[1]
				Nkey1=Nkey1+1
			if key1[0].strip() == "plength" and d[0] != "#":
				plength=np.asarray(key1[1].split(), dtype=int)
				Nkey1=Nkey1+1
			if key1[0].strip() == "raw_params" and d[0] != "#":
				raw_params=np.asarray(key1[1].split(), dtype=float)
				Nkey1=Nkey1+1
			# Deal with global parameters specific to mixed modes 
			logic= key1[0].strip() == "model_type"      or key1[0].strip() == "Dnu_p"  or key1[0].strip() == "epsilon_p" or key1[0].strip() == "delta0l"
			logic= logic or key1[0].strip() == "alpha_p"  or key1[0].strip() == "nmax"  or key1[0].strip() == "DPl" or key1[0].strip() == "alpha_g" 
			logic= logic or key1[0].strip() == "q_star"  or key1[0].strip() == "sigma_p"  or key1[0].strip() == "nu_p" or key1[0].strip() == "nu_g" 
			if logic and d[0] != "#":
				# nu_p and nu_g are expected to be vectors... these need to be splitted using the ',' separator... in the else section
				#global_mixed_name_params.append(key1[0].strip())
				if key1[0].strip() != "nu_p" and key1[0].strip() != "nu_g":
					#global_mixed_params.append(float(key1[1]))
					mixed_modes_params_dic[key1[0].strip()]=float(key1[1])
				else:
					#global_mixed_params.append(np.asarray(key1[1].split(","), dtype=float))
					mixed_modes_params_dic[key1[0].strip()]=np.asarray(key1[1].split(","), dtype=float)
				Nkey1=Nkey1+1
		if len(key1) > 2:
			print("Error when interpreting the line:", d)
			print("     Multiple '=' symbols found, which we are unable to interpret")
			print("     Only one = symbol per line should be used to declare a variable name")
			exit()
		if len(key2) >= 2: # This indicates that we found the symbol + some extra stuff after. The case len(key2) == 1 is ignored (empty line or no symbol)
			if key2[1].strip() == "Spectrum parameters. Frequency range min/max (microHz) / Resolution (microHz)":
				i=i+1 # Go to the next line, which has the data
				d=data[i] # Update the data
				xrange_params=np.asarray(d.split(), dtype=float)
				if i < len(data): # Consider the case where this block is at the end... then no need to update de data
					i=i+1 # Go to the next line, which has the data
					d=data[i] # Update the data
					key1=d.split('=')
					key2=d.split('#')
				Nkey2=Nkey2+1
			# Look for the combination of four successive words in the line stating with #
			if key2[1].split()[0].strip() == "Input" and  key2[1].split()[1].strip() == "mode" and key2[1].split()[2].strip() == "parameters." and key2[1].split()[3].strip() == "degree":
				#print('d =', d)
				# Get the name of the parameters as written in the model file.
				# We first merge the section that has the name because the separator is '/' NOT ' '
				tmp=""
				for p in key2[1].split()[3:]:
					tmp=tmp+p
				# We (re)split according to the expected separator "/"
				mode_params_names=tmp.split("/")
				i=i+1 # Go to the next line, which has the first line of data
				d=data[i] # Update the data
				params_list=[]
				while d.strip()[0] != "#" and i<len(data): # Read the table that follows until we reach a comment symbol
					# Make a list of array. Each list entry is a line of the tab... will be converted into a 2D array later
					# once we know the size of the array in x and y
					tmp=d.split()
					if len(tmp) == len(mode_params_names):
						params_list.append(np.asarray(tmp, dtype=float))
					else:
						print(" Error: The lines that contain the parameters of each modes do not have a constant or expected size")
						print("        There might be an issue in the structure of the matrix of data written by the used TAMCMC model function")
						print("        Please check also that the labels given in the used TAMCMC model function is consistent with the number of parameters entries")
						print(" Debug information:")
						print("   - Expected params_names: ", mode_params_names)
						print("   - Inconsistent line    : ", tmp)
						exit()
					i=i+1 # Go to the next line, which has the data
					d=data[i] # Update the data
				# We should now have a complete list of the mode params... we can organise them in a 2 Numpy Matrix
				mode_params=np.zeros((len(params_list), len(mode_params_names)))
				for j in range(len(params_list)):
					mode_params[j,:]=params_list[j]
				key1=d.split('=')
				key2=d.split('#')
				Nkey2=Nkey2+1			
			if key2[1].strip() == "Input mode parameters. H0 , tau_0 , p0 / H1, tau_1, p1 / N0. Set at -1 if not used. -2 means that the parameter is not even written on the file (because irrelevant).":
				#print('d =', d)
				i=i+1 # Go to the next line, which has the first line of data
				d=data[i] # Update the data	
				noise_params=np.zeros((4, 3))
				for j in range(4):
					noise_params[j,:]=np.asarray(d.split())
					i=i+1
					d=data[i]
				if i < len(data)-1: # Consider the case where this block is at the end... then no need to update de data
					i=i+1
					d=data[i]
				Nkey2=Nkey2+1
			# --- Section Specifically for the case of mixed modes: Handling the table ---
			if key2[1].strip() == "Mixed mode local parameters.":
				i=i+1 # Go to the next line, which has the first line of data
				d=data[i] # Update the data
				key2=d.split("#")
				#print('d =', d)
				# Get the name of the parameters as written in the model file.
				# We first merge the section that has the name because the separator is '/' NOT ' '
				# Expecting : el / fl1_asymptotic / included? / spline_corr / ksi_pg / h1_h0 / Hl1p_all / Hl1_all / Wl1_all 
				tmp=""
				for p in key2[1].split():
					tmp=tmp+p
				# We (re)split according to the expected separator "/"
				mixed_mode_params_names=tmp.split("/")
				i=i+1 # Go to the next line, which has the first line of data
				d=data[i] # Update the data
				params_list=[]
				while d.strip()[0] != "#" and i<len(data): # Read the table that follows until we reach a comment symbol or the end of the file
					# Make a list of array. Each list entry is a line of the tab... will be converted into a 2D array later
					# once we know the size of the array in x and y
					tmp=d.split()
					print(tmp)
					if len(tmp) == len(mixed_mode_params_names):
						params_list.append(np.asarray(tmp, dtype=float))
					else:
						print(" Error: The lines that contain the parameters of each mixed modes do not have a constant or expected size")
						print("        There might be an issue in the structure of the matrix of data written by the used TAMCMC model function")
						print("        Please check also that the labels given in the used TAMCMC model function is consistent with the number of parameters entries")
						print(" Debug information:")
						print("   - Expected params_names: ", mixed_mode_params_names)
						print("   - Inconsistent line    : ", tmp)
						exit()
					i=i+1 # Go to the next line, which has the data
					d=data[i] # Update the data
					if d == "" and i == len(data)-1:
						#print('Warning: Detected a final empty line. Hitting the end of the file.')
						d="# " # adding a dummy marker to avoid crash and iterate i
						i=i+1
				# We should now have a complete list of the mode params... we can organise them in a 2 Numpy Matrix
				mixed_mode_params=np.zeros((len(params_list), len(mixed_mode_params_names)))
				for j in range(len(params_list)):
					mixed_mode_params[j,:]=params_list[j]
				# We now include the mixed_mode_params table into the dictionary mixed_modes_params_dic
				mixed_modes_params_dic["data"]=mixed_mode_params
				mixed_modes_params_dic["labels"]=mixed_mode_params_names
				key1=d.split('=')
				key2=d.split('#')
				Nkey2=Nkey2+1			
		i=i+1
	if Nkey1 != Nkey1_expected:
		print("Error in the key '=': We expect exactly ", Nkey1_expected, " keys but we got ", Nkey1)
		print("   This could be due to an improper structure of the parameter file.")
		print("   If params.model is for a model with mixed modes, check that this one is supported by the function")
		print("   Debug required")
		exit()
	return modelname, plength, raw_params, mode_params, noise_params, xrange_params, mode_params_names, mixed_modes_params_dic

def read_getmodel_out(file_in):
	# Function the data within the text output files generated by getmodel.cpp
	f=open(file_in)
	txt=f.read()
	f.close()
	data=txt.split('\n')
	x=[]
	y=[]
	for d in data[1:]:
		if d != '':
			v=d.split()
			print(d)
			x.append(v[0])
			y.append(v[1])	
	return np.asarray(x, dtype=float), np.asarray(y, dtype=float)

def read_getmodel_out_v2(file_in):
	f=open(file_in, 'r')
	data=f.read()
	f.close()
	txt=data.split('\n')
	nmodels=len(txt[0].split()) - 2
	#
	x=np.zeros(len(txt))
	y=np.zeros(len(txt))
	if nmodels > 0:
		m=np.zeros((nmodels, len(txt)))
	i=0
	for t in txt:
		line=t.split()
		if len(line)>0:
			x[i]=line[0]
			y[i]=line[1]
			for j in range(nmodels):
				m[j,i]=line[2+j]
			i=i+1
	x=x[0:i-1]
	y=y[0:i-1]
	if nmodels > 0:
		m=m[:,0:i-1]
	else:
		m=[]
	return x,y, m

def read_bin2txt_out(file_in):
	# Function that get the header and the data within the text output files generated by bin2txt.cpp
	f=open(file_in)
	txt=f.read()
	f.close()
	data=txt.split('\n')
	varname=data[0].split('=')[1:][0]
	samples=[]
	for d in data[1:]:
		if d != '':
			samples.append(d)	
	return np.asarray(samples), varname

def read_plength(file_in):
	# Function that read the plength.txt file created by bin2txt
	f=open(file_in)
	txt=f.read()
	f.close()
	data=txt.split('\n')
	plength=[]
	for d in data: # A loop to remove any white space, if present
		if d != "":
			plength.append(d)
	return np.asarray(plength, dtype=int)

def getstats_txt(filename):
	'''
		A function that is able to read the text file created when running getstats (the tamcmc program that unpack data from the bin files)
	'''
	f=open(filename)
	txt=f.read()
	f.close()
	data=txt.split('\n')
	header=[]
	loglikelihood=[]
	logprior=[]
	logposterior=[]
	for d in data:
		s=d.split()
		if len(s) !=0:
			if s[0] == '#':
				header.append(d)
			else:
				loglikelihood.append(float(s[0]))
				logprior.append(float(s[1]))
				logposterior.append(float(s[2]))
	labels=header[-1]
	header=header[0:-2]
	loglikelihood=np.asarray(loglikelihood)
	logprior=np.asarray(logprior)
	logposterior=np.asarray(logposterior)
	return loglikelihood, logprior, logposterior, header, labels


def get_files_list(rootdir, extension='.ASCII'):
	'''
		A tiny function that scan a directory in order to find all of 
		its files
	'''
	files=[]
	for x in os.listdir(rootdir):
		if x.endswith(extension):
			files.append(x)
	files=sorted(files, key=lambda x: int(x.split('.')[0]))
	return files


##########

def read_logposterior_tamcmc(dir_tamcmc_outputs, process_name, phase='A', chain=0):
	'''
		Read the logposterior file and return all of the logposterior probabilities
		Uses the getstats_bin() function to extract the data, convert them into text,
		read them with getstats_txt() and recover only what is relevant for MLCJ, ie
		the logposteriors (lpdf)
		dir_tamcmc_outputs: The roott directory that contains all of the outputs. The process outputs must be in a subdirectory of this directory
		core_filename: The name of the process that was ran (eg. 'aj_ARonly_Sun'). This is the name listed in the config_presets.cfg of the tamcmc program
		phase: The phase of the analysis
		chain: The chain index that need to be unpacked
		outfile: The name of the output file
	'''
	ll, lp, lpdf=getstats_bin(dir_tamcmc_outputs, process_name, phase=phase, chain=chain)
	return lpdf

def read_params_tamcmc(dir_tamcmc_outputs, process_name, phase='A', chain=0, first_index=0, period=1, epsi_iscte=False):
	'''
		Use bin2txt and shape them in a suitable way for MLCJ.py
		This function basically removes all of the constant terms.
		TO USE ONLY WITH MODELS FOR ACTIVITY. NOT FOR THE POWER SPECTRUM FITTING
	'''
	s, l, isfixed=bin2txt(dir_tamcmc_outputs, process_name, phase=phase, chain=chain, first_index=first_index, period=period, erase_tmp=True)
	# --- Keeps only epsilon_0 (if epsi_iscte == False), theta0 and delta ---
	if epsi_iscte == False:
		smcmc=s[:,0:3] # keep epsilon_0, theta0, delta
		labels=l[0:3]
	else:
		smcmc=s[:,1:3] # keep theta0 and delta
		labels=l[1:3]
	sinput=smcmc[0,:] # recover the initial values... this will be used to construct pref_all
	return smcmc, sinput,labels


def read_datafile(file_in):
	'''
		Read a data file used for the TAMCMC analysis
		If the file is a zip file, then it is assummed that within it, there is a data file,
		that is going to be extracted first before reading
		file_in: The file to read
	'''
	extension=os.path.splitext(file_in)[1]
	if extension == '.zip':
		with ZipFile(file_in, 'r') as zip:
			#files=zip.printdir()
			files=zip.namelist()
			count=0
			for f in files:
				ext=os.path.splitext(f)[1]
				if ext == '.data':
					txt=zip.read(f).decode('utf-8')
					count=count+1
			if count > 1:
				print('Error: There was multiple data files within the zip files read by read_datafile()')
				print("       Debug required. File read:", file_in)
				exit()
	if extension == ".data":
		f=open(file_in, 'r')
		txt=f.read()
		f.close()
	if extension != ".data" and  extension != ".zip":
		print("Error: The data file is neither a zip nor a data file")
		print("       Provided file: ", file_in)
		exit()
	data=txt.split('\n')
	Nlines=len(data)
	k=0
	header=[]
	for d in data:
		if d != "":
			key=d.strip()[0]
		else:
			key=""
		if key != "#" and key !='!' and key !='*' and key != "":
			line=d.split()
			if k == 0:
				output=np.zeros((Nlines, len(line)), dtype=float)
			output[k,:]=np.asarray(line, dtype=float)
			k=k+1
		else:
			header.append(d)
	if k < Nlines: # It means that there was a white line at the end of the file... need to remove it
		output=output[0:k,:]
	return output, header

def read_global_likelihood(filein, evidence_only=True, bootstrap_on=False):
	'''
		A tiny bit of code that extract the global likelihood from the global likelihood file.
		This file is within the diags directory and has for extension '_evidence.txt'
		filein: Input evidence file
		evidence_only: If True (default) only returns the evidence and an estimate of the error on it by
			difference with the mid-sampling
			Otherwise, return the full information on the function integrated to get the evidence (all of the data
			from the global_likelihood file)
		bootstrap_on: If False (default) the error is crudely estimated by taking the evidence at half of the table of samples. 
					  This is not the recommended way to measure error since >1.86.75. 
					  If True, the error is 
	'''
	f=open(filein)
	txt=f.read()
	f.close()
	data=txt.split('\n')
	header=[]
	params_names=[]
	params=[]
	table=[]
	Ntemperatures=-1
	for d in data:
		s=d.split()
		if len(s) !=0:
			if s[0] == '#':
				header.append(d)
			if s[0] == '!':
				p=str(s[1].split('=')[0])
				params_names.append(p)
				if p == "beta":
					l=d.split('=')[1].split() # Expect an array of values
					params.append(l)
					Ntemperatures=len(l)
				if p == 'interpolation_factor':
					l=s[1].split('=')[1] # Expect a single value
					params.append(l)
			if s[0] != '#' and s[0] != '!':
				if Ntemperatures == -1:
					print('Warning: Could not find the temperature range used for the calculation.')
					print('         Perhaps it appears after the table of values instead of before?')
					print('         User attention required. Pursuing...')
				if s[0] != []:
					table.append(s)
	table=np.asarray(table, dtype=float)
	if evidence_only == False:
		return table, params, params_names
	#
	if bootstrap_on == False: # Legacy case, where the uncertainty is crudely estimated
		evidence=table[-1,-1]
		Nmid=int(np.fix(len(table[:,0])/2)) -1
		err_evidence=np.abs(evidence - table[Nmid, -1])
	else: # Case where we expect that the table contains all of the sample of the bootstrap result
		evidence=np.median(table[:,1]) # Likelihood median
		err_evidence=np.std(table[:,1])
		#evidence=np.median(table[:,-1])
		#err_evidence=np.std(table[:,-1])
	return evidence, err_evidence

def version():
	print('read_output_tacmcmc version 2.231')
	print("  Changes since 2.231: ")
	print("     - Update of getstats to handle the new option format")
	print('  Changes since 2.23: ')
	print("     - Adding the getevidence which calls the C++ program of same name available since >1.86.75. Note that outputs of C++ getevidence are readable with read_global_likelihood()")
	print("     - Using os.path.join() instead of a the + operation to deal with directories")
	print("     - Adding verbose=False to calls to C++ program to avoid too much output text. verbose=True is now for debugging")
	print('  Changes since 2.22: ')
	print('     - Modifying the function read_getmodel_out to handle more than two columns outputs')
	print('     - Removing process.communicate in case of error within bin2txt: This was obselete')
	print('  Changes since 2.21: ')
	print('     - Adding cpp_version argument in bin2txt() to ensure cross-compatibility between 1.84.X and >1.85.0')
	print('  Changes since 2.1: ')
	print('     - Adding read_global_likelihood() which allows you to read the output TAMCMC files that contain the evidence')
	print('  Changes since 2.0: ')
	print('     - Adding data_type as argument of the getmodel_bin function: It allows to either provide a data file or use a linear x-axis generated by the code (previously this only was available)')
	print('  Changes since 1.0: ')
	print('     - Replacing Popen to call C++ processes by call: This allows to hand any other execution prior the C++ process finished')
	print('     - bin2txt returns 3 outputs now. The new output is "isfixed": It specifies (False,True) if a parameter was fixed or not')
	print('     - In bin2txt, remove all white spaces from the varname. This could cause issues when looking at a variable name')
	print('     - Fixing an issue with the extraction of variable names by read_bin2txt_out() (these were in a list of list, instead of a simple list')
	print('     - getstats_bin can now handle first_sample, period in a similar way than bin2txt. WARNING: REQUIRES TAMCMC v>1.83.5')
	print('     - Adding the option "outdir" for getstats and bin2txt so that the user can choose the output directory for the ascii results')
	print('     - get_files_list now returns properly sorted list of files according to their numbers')
	print('     - Adding getmodel_bin: It allows to execute getmodel within python. REQUIRES TAMCMC v>1.83.6')
	print('     - Adding read_plength in order to read the plength.txt file that is generated by bin2txt')
	print('     - In bin2txt, adding an option to extract also plength within bin2txt. The default is False, to ensure compatibility with old implementations')
	print('     - Adding a read_datafile, to read input data files of the TAMCMC. Accepts as well zipped version of that file')
	print('     - read_paramsfile_getmodel() now handled the new standard of params.model file that can contain mixed modes information')

version()